"""
test_pipeline.py
================
Script para probar la integraciÃ³n completa:
    1. config.py (rutas centralizadas)
    2. kaggle_downloader.py (descarga de Kaggle)
    3. data_loader.py (lectura de datos)

DATASET: Big Startup Success/Fail Dataset from Crunchbase
OBJETIVO: Preparar datos para anÃ¡lisis de inversiÃ³n en startups

UBICACIÃ“N: tests/test_pipeline.py o notebooks/00_data_setup.ipynb
"""

# ============================================================
# PASO 1: IMPORTACIONES
# ============================================================

print("\n" + "=" * 70)
print("ğŸš€ PIPELINE DE DATOS: DESCARGA Y LECTURA")
print("=" * 70)

# Importar mÃ³dulos del proyecto
from src.data.kaggle_downloader import download_from_kaggle
from src.data.data_loader import load_raw
from src.data.config import show_config
import pandas as pd

# ============================================================
# PASO 2: VERIFICAR CONFIGURACIÃ“N DEL PROYECTO
# ============================================================

print("\nğŸ“‹ PASO 1: Verificando configuraciÃ³n del proyecto...\n")
show_config()

# ============================================================
# PASO 3: DESCARGAR DATASET DE KAGGLE
# ============================================================

print("\nğŸ“¥ PASO 2: Descargando dataset de Kaggle...\n")

#! Dataset de Crunchbase con informaciÃ³n de startups - Cambio acÃ¡
DATASET_ID = 'sidraaazam/analyzing-student-stress-factors'

# Descargar (se salta si ya existe)
try:
    dataset_path = download_from_kaggle(DATASET_ID)
    print(f"\nâœ… Dataset disponible en: {dataset_path}")
except Exception as e:
    print(f"\nâŒ Error descargando dataset: {e}")
    print("\nğŸ’¡ SOLUCIÃ“N:")
    print("   1. Verifica tu conexiÃ³n a internet")
    print("   2. Ejecuta: verify_kaggle_setup()")
    exit(1)

# ============================================================
# PASO 4: CARGAR DATOS CON data_loader
# ============================================================

print("\nğŸ“Š PASO 3: Cargando datos en memoria...\n")

#! Nombre del archivo principal del dataset
FILENAME = 'Student Stress Factors (2).csv'

try:
    # Cargar usando load_raw (bÃºsqueda recursiva en data/raw/)
    df_startups = load_raw(FILENAME)

    print("\n" + "=" * 70)
    print("âœ… DATOS CARGADOS EXITOSAMENTE")
    print("=" * 70)

except FileNotFoundError as e:
    print(f"\nâŒ Error: {e}")
    print("\nğŸ’¡ Archivos disponibles en data/raw/:")
    from pathlib import Path
    from src.data.config import RAW_DATA_DIRECTORY

    for file in RAW_DATA_DIRECTORY.rglob('*.csv'):
        print(f"   â€¢ {file.relative_to(RAW_DATA_DIRECTORY)}")
    exit(1)

# ============================================================
# PASO 5: INSPECCIÃ“N INICIAL DE LOS DATOS
# ============================================================

print("\nğŸ“ˆ PASO 4: InformaciÃ³n bÃ¡sica del dataset\n")

# Dimensiones
print(f"ğŸ“ Dimensiones:")
print(f"   Filas (startups): {df_startups.shape[0]:,}")
print(f"   Columnas (variables): {df_startups.shape[1]}")

# Columnas disponibles
print(f"\nğŸ“‹ Columnas disponibles ({df_startups.shape[1]}):")
for i, col in enumerate(df_startups.columns, 1):
    print(f"   {i:2d}. {col}")

# Tipos de datos
print(f"\nğŸ”¢ Tipos de datos:")
print(df_startups.dtypes)

# Valores nulos
print(f"\nâ“ Valores nulos por columna:")
nulls = df_startups.isnull().sum()
nulls_pct = (nulls / len(df_startups) * 100).round(2)
null_summary = pd.DataFrame({
    'Nulos': nulls,
    'Porcentaje': nulls_pct
}).sort_values('Nulos', ascending=False)
print(null_summary[null_summary['Nulos'] > 0])

# Primeras filas
print(f"\nğŸ‘€ Primeras 5 filas del dataset:")
print(df_startups.head())

# InformaciÃ³n de memoria
memory_mb = df_startups.memory_usage(deep=True).sum() / (1024 ** 2)
print(f"\nğŸ’¾ Uso de memoria: {memory_mb:.2f} MB")

# ============================================================
# PASO 6: RESUMEN FINAL
# ============================================================

print("\n" + "=" * 70)
print("ğŸ¯ RESUMEN DEL PIPELINE")
print("=" * 70)
print(f"âœ… Dataset descargado: {DATASET_ID}")
print(f"âœ… Archivo cargado: {FILENAME}")
print(f"âœ… Registros disponibles: {len(df_startups):,} startups")
print(f"âœ… Variables disponibles: {df_startups.shape[1]}")
print("\nğŸ’¡ Variable 'df_startups' lista para anÃ¡lisis")
print("=" * 70)

# ============================================================
# PASO 7: GUARDAR REFERENCIA PARA ANÃLISIS
# ============================================================

print("\nğŸ“Œ El DataFrame estÃ¡ disponible como: df_startups")
print("ğŸš¦ Esperando instrucciones para anÃ¡lisis de insights...\n")