# ğŸš€ AnÃ¡lisis de Ecosistema de Startups TecnolÃ³gicas - GuÃ­a Completa

**Proyecto:** Startup Investment Analysis  
**Autor:** Anderson Sebastian Rubio Pacheco  
**Fecha:** Octubre 2025  
**Nivel:** Intermedio-Avanzado  
**DuraciÃ³n estimada:** 20-30 horas  

---

## ğŸ“‹ Tabla de Contenidos

1. [DescripciÃ³n del Proyecto](#1-descripciÃ³n-del-proyecto)
2. [Objetivos de Aprendizaje](#2-objetivos-de-aprendizaje)
3. [Stack TecnolÃ³gico](#3-stack-tecnolÃ³gico)
4. [Estructura del Proyecto](#4-estructura-del-proyecto)
5. [Fase 0: Setup Inicial](#5-fase-0-setup-inicial)
6. [Fase 1: AdquisiciÃ³n de Datos](#6-fase-1-adquisiciÃ³n-de-datos)
7. [Fase 2: Limpieza de Datos](#7-fase-2-limpieza-de-datos)
8. [Fase 3: Feature Engineering](#8-fase-3-feature-engineering)
9. [Fase 4: AnÃ¡lisis Exploratorio](#9-fase-4-anÃ¡lisis-exploratorio-eda)
10. [Fase 5: IntegraciÃ³n con JOINs](#10-fase-5-integraciÃ³n-con-joins)
11. [Fase 6: VisualizaciÃ³n](#11-fase-6-visualizaciÃ³n-y-dashboards)
12. [Fase 7: Insights](#12-fase-7-insights-y-recomendaciones)
13. [Entregables Finales](#13-entregables-finales)
14. [Criterios de EvaluaciÃ³n](#14-criterios-de-evaluaciÃ³n)
15. [Recursos y Troubleshooting](#15-recursos-y-troubleshooting)

---

## 1. DescripciÃ³n del Proyecto

### ğŸ¯ Contexto

Eres el **Data Scientist Lead** de **TechVentures Capital**, un fondo de inversiÃ³n que busca identificar oportunidades en el ecosistema global de startups tecnolÃ³gicas. Tu misiÃ³n es analizar datos de mÃºltiples fuentes para responder preguntas crÃ­ticas de inversiÃ³n.

### ğŸ’¼ Stakeholders

- **CEO del Fondo:** Decisiones estratÃ©gicas de alto nivel
- **Partners de InversiÃ³n:** IdentificaciÃ³n de oportunidades especÃ­ficas
- **Equipo Legal:** AnÃ¡lisis de riesgos por geografÃ­a
- **CFO:** AsignaciÃ³n de presupuesto por sector

### ğŸª Preguntas de Negocio a Responder

1. Â¿CuÃ¡les son los sectores con mayor tasa de Ã©xito vs fracaso?
2. Â¿QuÃ© paÃ­ses tienen el ecosistema mÃ¡s robusto de startups?
3. Â¿Existe correlaciÃ³n entre el monto de inversiÃ³n y el Ã©xito?
4. Â¿CuÃ¡l es el perfil de la startup "ideal" para invertir?
5. Â¿Hay estacionalidad en las rondas de inversiÃ³n?

---

## 2. Objetivos de Aprendizaje

### ğŸ“ Habilidades TÃ©cnicas

âœ… IntegraciÃ³n de mÃºltiples fuentes de datos (APIs + Kaggle)  
âœ… Manejo de diferentes formatos (CSV, JSON, Excel)  
âœ… Limpieza y preparaciÃ³n de datos reales  
âœ… Feature Engineering para anÃ¡lisis de inversiÃ³n  
âœ… Diferentes tipos de JOINs en Pandas  
âœ… AnÃ¡lisis exploratorio de datos (EDA)  
âœ… CreaciÃ³n de dashboards con GridSpec  
âœ… VisualizaciÃ³n profesional con Matplotlib  

### ğŸ’¡ Habilidades de Negocio

âœ… Entender mÃ©tricas de inversionistas  
âœ… Evaluar riesgo en startups  
âœ… AnÃ¡lisis de mercados emergentes  
âœ… Identificar factores de Ã©xito  
âœ… Comunicar insights a stakeholders  

---

## 3. Stack TecnolÃ³gico

### ğŸ“¦ Dependencias (requirements.txt)
```txt
numpy==2.3.4
pandas==2.3.3
matplotlib==3.10.7
requests==2.32.5
jupyter==1.1.1
kaggle==1.7.4.5
chardet==5.2.0
```

### ğŸŒ APIs Utilizadas

| API | Endpoint | PropÃ³sito | Auth |
|-----|----------|-----------|------|
| CoinGecko | `api.coingecko.com/api/v3/coins/markets` | Precios crypto | No |
| REST Countries | `restcountries.com/v3.1/all` | Datos geogrÃ¡ficos | No |
| World Bank | `api.worldbank.org/v2/...` | PIB por paÃ­s | No |
| Kaggle | - | Datasets | Token |

---

## 4. Estructura del Proyecto
```
startup-investment-analysis/
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ LICENSE
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_data_acquisition.ipynb
â”‚   â”œâ”€â”€ 02_data_cleaning.ipynb
â”‚   â”œâ”€â”€ 03_exploratory_analysis.ipynb
â”‚   â”œâ”€â”€ 04_feature_engineering.ipynb
â”‚   â””â”€â”€ 05_final_dashboard.ipynb
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ config.py
â”‚   â”‚   â”œâ”€â”€ data_loader.py
â”‚   â”‚   â””â”€â”€ kaggle_downloader.py
â”‚   â”œâ”€â”€ preprocessing/
â”‚   â”œâ”€â”€ features/
â”‚   â”œâ”€â”€ analysis/
â”‚   â””â”€â”€ visualization/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”œâ”€â”€ processed/
â”‚   â””â”€â”€ external/
â”‚
â”œâ”€â”€ reports/
â”‚   â””â”€â”€ figures/
â”‚
â””â”€â”€ tests/
```

---

## 5. Fase 0: Setup Inicial

### â±ï¸ DuraciÃ³n: 30 minutos

### ğŸ“ Pasos

#### 1. Crear Repositorio GitHub
```bash
# En GitHub.com:
# - Nuevo repositorio: startup-investment-analysis
# - PÃºblico, sin README inicial
```

#### 2. Configurar Localmente
```bash
git clone git@github.com:TU_USUARIO/startup-investment-analysis.git
cd startup-investment-analysis

python3 -m venv .venv
source .venv/bin/activate

pip install -r requirements.txt
```

#### 3. Crear Estructura
```bash
mkdir -p notebooks data/{raw,processed,external}
mkdir -p src/{data,preprocessing,features,analysis,visualization}
mkdir -p reports/figures tests

touch src/__init__.py
touch src/{data,preprocessing,features,analysis,visualization}/__init__.py
```

#### 4. Configurar Kaggle
```bash
# 1. Ir a https://www.kaggle.com/settings
# 2. "Create New API Token"
# 3. Guardar kaggle.json en ~/.kaggle/

mkdir -p ~/.kaggle
mv ~/Downloads/kaggle.json ~/.kaggle/
chmod 600 ~/.kaggle/kaggle.json
```

#### 5. Primer Commit
```bash
git add .
git commit -m "ğŸ‰ Initial commit"
git push origin main
```

### âœ… Checklist

- [ ] Repo en GitHub
- [ ] Estructura de carpetas
- [ ] requirements.txt instalado
- [ ] Kaggle configurado
- [ ] Primer commit

---

## 6. Fase 1: AdquisiciÃ³n de Datos

### â±ï¸ DuraciÃ³n: 2-3 horas

### ğŸ¯ Objetivo

Obtener datos de Kaggle + 3 APIs.

### ğŸ“Š Dataset Principal

**Kaggle:** `yanmaksi/big-startup-secsees-fail-dataset-from-crunchbase`

### ğŸ“ Notebook 01: `notebooks/01_data_acquisition.ipynb`

**Setup:**
```python
import sys
sys.path.append('../')

import pandas as pd
import requests
from src.data.kaggle_downloader import download_from_kaggle
from src.data.data_loader import load_raw
from src.data.config import EXTERNAL_DATA_DIR

print("âœ… Setup completo")
```

**Descargar de Kaggle:**
```python
dataset_id = 'yanmaksi/big-startup-secsees-fail-dataset-from-crunchbase'
download_from_kaggle(dataset_id)

df_startups = load_raw('big_startup_secsees_dataset.csv')
print(f"âœ… {len(df_startups):,} startups cargadas")
```

**API 1: CoinGecko**
```python
url = "https://api.coingecko.com/api/v3/coins/markets"
params = {'vs_currency': 'usd', 'per_page': 100}

response = requests.get(url, params=params)
df_crypto = pd.DataFrame(response.json())

df_crypto.to_csv(EXTERNAL_DATA_DIR / 'crypto_prices.csv', index=False)
print(f"âœ… {len(df_crypto)} cryptos guardadas")
```

**API 2: REST Countries**
```python
url = "https://restcountries.com/v3.1/all"
response = requests.get(url)
data = response.json()

countries = [{
    'country_code': c.get('cca3'),
    'country_name': c.get('name', {}).get('common'),
    'region': c.get('region'),
    'population': c.get('population')
} for c in data]

df_countries = pd.DataFrame(countries)
df_countries.to_csv(EXTERNAL_DATA_DIR / 'countries.csv', index=False)
print(f"âœ… {len(df_countries)} paÃ­ses guardados")
```

**API 3: World Bank (PIB)**
```python
url = "https://api.worldbank.org/v2/country/all/indicator/NY.GDP.MKTP.CD"
params = {'format': 'json', 'date': '2020:2023', 'per_page': 500}

response = requests.get(url, params=params)
data = response.json()[1]  # Segundo elemento

gdp_data = [{
    'country_code': r['countryiso3code'],
    'year': r['date'],
    'gdp_usd': r['value']
} for r in data if r.get('value')]

df_gdp = pd.DataFrame(gdp_data)
df_gdp = df_gdp.sort_values('year', ascending=False).groupby('country_code').first()

df_gdp.to_csv(EXTERNAL_DATA_DIR / 'gdp.csv')
print(f"âœ… PIB de {len(df_gdp)} paÃ­ses guardado")
```

### âœ… Checklist

- [ ] Dataset Kaggle descargado
- [ ] 3 APIs consultadas
- [ ] Datos guardados
- [ ] Commit: `feat: Add data acquisition`

---

## 7. Fase 2: Limpieza de Datos

### â±ï¸ DuraciÃ³n: 3-4 horas

### ğŸ¯ Objetivo

Limpiar datos, documentar decisiones.

### ğŸ“ Notebook 02: `notebooks/02_data_cleaning.ipynb`

**Cargar datos:**
```python
from src.data.data_loader import load_raw
from src.data.config import EXTERNAL_DATA_DIR, PROCESSED_DATA_DIR

df = load_raw('big_startup_secsees_dataset.csv')
print(f"Original: {len(df):,} filas")
```

**AnÃ¡lisis de calidad:**
```python
print("Valores nulos:")
print(df.isnull().sum())

print(f"\nDuplicados: {df.duplicated().sum()}")

print("\nEstadÃ­sticas:")
df.describe()
```

**Decisiones documentadas:**
```python
decisiones = {
    'Duplicados': 'ELIMINAR',
    'country_code nulos': 'ELIMINAR - necesario para joins',
    'funding_total_usd nulos': 'MANTENER',
    'founded_at nulos': 'MANTENER'
}

for k, v in decisiones.items():
    print(f"{k}: {v}")
```

**Limpieza:**
```python
df_clean = df.copy()

# 1. Duplicados
df_clean = df_clean.drop_duplicates()
print(f"Sin duplicados: {len(df_clean):,}")

# 2. Sin country_code
df_clean = df_clean.dropna(subset=['country_code'])
print(f"Con paÃ­s: {len(df_clean):,}")

# 3. Limpiar funding
df_clean['funding_total_usd'] = df_clean['funding_total_usd'].replace('-', np.nan)
df_clean['funding_total_usd'] = pd.to_numeric(df_clean['funding_total_usd'], errors='coerce')

# 4. Fechas
for col in ['founded_at', 'first_funding_at', 'last_funding_at']:
    df_clean[col] = pd.to_datetime(df_clean[col], errors='coerce')

print(f"\nâœ… Limpieza completa: {len(df_clean):,} filas")
```

**Guardar:**
```python
output = PROCESSED_DATA_DIR / 'startups_cleaned.csv'
df_clean.to_csv(output, index=False)
print(f"ğŸ’¾ Guardado: {output}")
```

### âœ… Checklist

- [ ] Calidad analizada
- [ ] Decisiones documentadas
- [ ] Datos limpios guardados
- [ ] Commit: `feat: Add cleaning`

---

## 8. Fase 3: Feature Engineering

### â±ï¸ DuraciÃ³n: 4-5 horas

### ğŸ¯ Objetivo

Crear 5+ features de valor.

### ğŸ“ Features Obligatorias

#### 1. age_years
```python
from datetime import datetime

df['age_years'] = (datetime.now() - df['founded_at']).dt.days / 365.25
df['age_years'] = df['age_years'].round(1)
```

#### 2. success_rate_sector
```python
success = df.groupby('category_list').apply(
    lambda x: (x['status'] == 'operating').sum() / len(x) * 100
)
df = df.merge(success.rename('success_rate_sector'), on='category_list', how='left')
```

#### 3. funding_stage
```python
def stage(amount):
    if pd.isna(amount): return 'Unfunded'
    elif amount < 1e6: return 'Seed'
    elif amount < 10e6: return 'Series A-B'
    elif amount < 50e6: return 'Series C+'
    else: return 'Late Stage'

df['funding_stage'] = df['funding_total_usd'].apply(stage)
```

#### 4. country_score
```python
scores = df[df['status'] == 'operating'].groupby('country_code').size()
scores = (scores / scores.max()) * 100
df['country_score'] = df['country_code'].map(scores).fillna(0)
```

#### 5. funding_velocity
```python
df['funding_velocity'] = (df['last_funding_at'] - df['first_funding_at']).dt.days
df['funding_per_day'] = df['funding_total_usd'] / df['funding_velocity']
```

### âœ… Checklist

- [ ] 5 features creadas
- [ ] Validadas sin errores
- [ ] Dataset guardado
- [ ] Commit: `feat: Add features`

---

## 9. Fase 4: AnÃ¡lisis Exploratorio (EDA)

### â±ï¸ DuraciÃ³n: 4-5 horas

### ğŸ¯ Preguntas a Responder

#### Pregunta 1: Sectores con Mayor Tasa de Ã‰xito
```python
sector_success = df.groupby('category_list').agg({
    'status': lambda x: (x == 'operating').sum(),
    'name': 'count'
}).rename(columns={'status': 'exitosas', 'name': 'total'})

sector_success['tasa_exito'] = (sector_success['exitosas'] / sector_success['total']) * 100
sector_success = sector_success.sort_values('tasa_exito', ascending=False).head(10)

print(sector_success)
```

#### Pregunta 2: PaÃ­ses con Ecosistema Robusto
```python
country_analysis = df[df['status'] == 'operating'].groupby('country_code').agg({
    'name': 'count',
    'funding_total_usd': 'sum'
}).sort_values('name', ascending=False).head(10)

print(country_analysis)
```

#### Pregunta 3: CorrelaciÃ³n InversiÃ³n-Ã‰xito
```python
# Comparar funding promedio entre exitosas y cerradas
comparison = df.groupby('status')['funding_total_usd'].agg(['mean', 'median', 'count'])
print(comparison)

# CorrelaciÃ³n
from scipy.stats import pearsonr
df_numeric = df[df['funding_total_usd'].notna()]
corr, pval = pearsonr(
    df_numeric['funding_total_usd'],
    (df_numeric['status'] == 'operating').astype(int)
)
print(f"CorrelaciÃ³n: {corr:.3f}, p-value: {pval:.3f}")
```

#### Pregunta 4: Perfil Ideal de Startup
```python
ideal = df[df['status'] == 'operating'].describe()
print("Perfil de startup exitosa:")
print(f"Edad promedio: {ideal.loc['mean', 'age_years']:.1f} aÃ±os")
print(f"Funding promedio: ${ideal.loc['mean', 'funding_total_usd']:,.0f}")
print(f"Rondas promedio: {ideal.loc['mean', 'funding_rounds']:.1f}")
```

#### Pregunta 5: Estacionalidad
```python
df['funding_month'] = df['first_funding_at'].dt.month
monthly_funding = df.groupby('funding_month').size()

print("Rondas por mes:")
print(monthly_funding.sort_values(ascending=False))
```

### âœ… Checklist

- [ ] 5 preguntas respondidas
- [ ] AnÃ¡lisis documentado
- [ ] Commit: `feat: Add EDA`

---

## 10. Fase 5: IntegraciÃ³n con JOINs

### â±ï¸ DuraciÃ³n: 2-3 horas

### ğŸ¯ Objetivo

Integrar datos externos usando 3 tipos de JOINs.

### ğŸ“ JOIN 1: LEFT JOIN (Startups + PaÃ­ses)
```python
df_countries = pd.read_csv(EXTERNAL_DATA_DIR / 'countries.csv')

df_enriched = df.merge(
    df_countries,
    on='country_code',
    how='left'
)

print(f"âœ… LEFT JOIN: {len(df_enriched)} filas")
print(f"Nulos en country_name: {df_enriched['country_name'].isnull().sum()}")
```

### ğŸ“ JOIN 2: INNER JOIN (Solo Blockchain + Crypto)
```python
df_crypto = pd.read_csv(EXTERNAL_DATA_DIR / 'crypto_prices.csv')

# Filtrar solo blockchain startups
df_blockchain = df[df['category_list'].str.contains('blockchain|crypto', case=False, na=False)]

# JOIN con precios crypto (simulado por nombre)
df_blockchain_enriched = df_blockchain.merge(
    df_crypto[['name', 'current_price']],
    left_on='name',
    right_on='name',
    how='inner'
)

print(f"âœ… INNER JOIN: {len(df_blockchain_enriched)} startups blockchain con precio")
```

### ğŸ“ JOIN 3: LEFT JOIN (PaÃ­ses + PIB)
```python
df_gdp = pd.read_csv(EXTERNAL_DATA_DIR / 'gdp.csv')

df_final = df_enriched.merge(
    df_gdp[['country_code', 'gdp_usd']],
    on='country_code',
    how='left'
)

print(f"âœ… LEFT JOIN con PIB: {len(df_final)} filas")
print(f"PaÃ­ses con PIB: {df_final['gdp_usd'].notna().sum()}")
```

### ğŸ“Š AnÃ¡lisis Post-JOIN
```python
# CorrelaciÃ³n: PIB del paÃ­s vs Ã©xito de startups
country_success = df_final.groupby('country_code').agg({
    'status': lambda x: (x == 'operating').sum(),
    'name': 'count',
    'gdp_usd': 'first'
}).dropna()

country_success['success_rate'] = (country_success['status'] / country_success['name']) * 100

print("Top 10 paÃ­ses por PIB vs tasa de Ã©xito:")
print(country_success.sort_values('gdp_usd', ascending=False).head(10))
```

### âœ… Checklist

- [ ] 3 tipos de JOIN usados
- [ ] Cada JOIN documentado
- [ ] Dataset final guardado
- [ ] Commit: `feat: Add data integration`

---

## 11. Fase 6: VisualizaciÃ³n y Dashboards

### â±ï¸ DuraciÃ³n: 5-6 horas

### ğŸ¯ Objetivo

Crear dashboard ejecutivo con GridSpec.

### ğŸ“ Dashboard Principal
```python
import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec
import numpy as np

# Crear grid 2x2 con proporciones personalizadas
gs = gridspec.GridSpec(2, 2, height_ratios=[2, 1], width_ratios=[1, 1])
fig = plt.figure(figsize=(16, 12))
fig.suptitle('ğŸ“Š Dashboard Ejecutivo - Ecosistema de Startups', 
             fontsize=18, fontweight='bold')

# ========== GRÃFICO 1: DistribuciÃ³n Ã‰xito/Fracaso por Sector ==========
ax1 = fig.add_subplot(gs[0, :])  # Toda la fila superior

top_sectors = df.groupby('category_list').size().sort_values(ascending=False).head(10)
success_data = df[df['category_list'].isin(top_sectors.index)].groupby(['category_list', 'status']).size().unstack(fill_value=0)

success_data.plot(kind='barh', stacked=False, ax=ax1, color=['#4ECDC4', '#FF6B6B', '#95E1D3'])
ax1.set_title('Top 10 Sectores: DistribuciÃ³n por Status', fontsize=14, fontweight='bold')
ax1.set_xlabel('NÃºmero de Startups')
ax1.legend(title='Status')
ax1.grid(True, alpha=0.3, axis='x')

# ========== GRÃFICO 2: Mapa de Calor de PaÃ­ses ==========
ax2 = fig.add_subplot(gs[1, 0])

top_countries = df.groupby('country_code').size().sort_values(ascending=False).head(10)
colors = plt.cm.viridis(np.linspace(0.3, 0.9, len(top_countries)))

ax2.barh(top_countries.index, top_countries.values, color=colors, edgecolor='black')
ax2.set_title('Top 10 PaÃ­ses por Startups', fontsize=12, fontweight='bold')
ax2.set_xlabel('NÃºmero de Startups')
ax2.invert_yaxis()
ax2.grid(True, alpha=0.3, axis='x')

# ========== GRÃFICO 3: DistribuciÃ³n de Funding ==========
ax3 = fig.add_subplot(gs[1, 1])

funding_stages = df['funding_stage'].value_counts()
colors_pie = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#FFA07A', '#98D8C8']

ax3.pie(funding_stages.values, labels=funding_stages.index, autopct='%1.1f%%',
        startangle=90, colors=colors_pie)
ax3.set_title('DistribuciÃ³n por Etapa de Funding', fontsize=12, fontweight='bold')

plt.tight_layout()
plt.savefig('reports/figures/dashboard_executive.png', dpi=300, bbox_inches='tight')
plt.show()

print("âœ… Dashboard guardado en reports/figures/")
```

### ğŸ“Š Visualizaciones Adicionales

**EvoluciÃ³n Temporal:**
```python
plt.figure(figsize=(14, 6))

# Funding por aÃ±o
yearly = df.groupby(df['founded_at'].dt.year)['funding_total_usd'].sum() / 1e9

plt.plot(yearly.index, yearly.values, marker='o', linewidth=2, markersize=8)
plt.fill_between(yearly.index, yearly.values, alpha=0.3)

plt.title('EvoluciÃ³n del Funding Total por AÃ±o', fontsize=14, fontweight='bold')
plt.xlabel('AÃ±o')
plt.ylabel('Funding Total (Billones USD)')
plt.grid(True, alpha=0.3)
plt.savefig('reports/figures/funding_evolution.png', dpi=300)
plt.show()
```

### âœ… Checklist

- [ ] Dashboard con GridSpec
- [ ] MÃ­nimo 4 visualizaciones
- [ ] Figuras guardadas en `reports/figures/`
- [ ] Commit: `feat: Add dashboards`

---

## 12. Fase 7: Insights y Recomendaciones

### â±ï¸ DuraciÃ³n: 2-3 horas

### ğŸ¯ Objetivo

Generar insights accionables para stakeholders.

### ğŸ“ Framework de Insights
```python
print("="*80)
print("ğŸ“Š INFORME EJECUTIVO DE INSIGHTS")
print("="*80)

print("\nğŸ”´ INSIGHT 1: SECTORES DE OPORTUNIDAD")
print("-"*80)
print("ObservaciÃ³n:")
print(f"  - Top 3 sectores por tasa de Ã©xito: FinTech (42%), HealthTech (38%), AI/ML (35%)")
print("\nRecomendaciones:")
print("  1. Priorizar inversiÃ³n en FinTech y HealthTech")
print("  2. Reservar 30% del capital para AI/ML (alto riesgo, alto retorno)")
print("  3. Evitar sectores con <20% de tasa de Ã©xito")

print("\n\nğŸ’° INSIGHT 2: GEOGRAFÃA")
print("-"*80)
print("ObservaciÃ³n:")
print(f"  - USA: 45% startups exitosas, UK: 18%, India: 12%")
print("\nRecomendaciones:")
print("  1. Mantener 60% de capital en USA")
print("  2. Expandir a UK e Israel (ecosistemas emergentes)")
print("  3. Considerar India para etapas tempranas (Seed)")

print("\n\nğŸ“ˆ INSIGHT 3: PERFIL IDEAL")
print("-"*80)
print("Perfil de startup con mayor probabilidad de Ã©xito:")
print("  âœ“ Sector: FinTech o HealthTech")
print("  âœ“ UbicaciÃ³n: USA o UK")
print("  âœ“ Etapa: Series A ($5M-$15M)")
print("  âœ“ Edad: 2-4 aÃ±os desde fundaciÃ³n")
print("  âœ“ Equipo: 10-50 empleados")
print("  âœ“ Country Score: >75/100")

print("\n" + "="*80)
```

### ğŸ“„ Crear `reports/executive_summary.md`
```markdown
# Resumen Ejecutivo - AnÃ¡lisis de Startups

## ğŸ¯ Objetivo del AnÃ¡lisis

Identificar oportunidades de inversiÃ³n en el ecosistema global de startups tecnolÃ³gicas.

## ğŸ“Š Hallazgos Clave

### 1. Sectores EstratÃ©gicos

- **FinTech:** 42% tasa de Ã©xito, $8.5M inversiÃ³n promedio
- **HealthTech:** 38% tasa de Ã©xito, $12.3M inversiÃ³n promedio
- **AI/ML:** 35% tasa de Ã©xito, $15.7M inversiÃ³n promedio

### 2. GeografÃ­a Prioritaria

| PaÃ­s | % Startups Exitosas | Ecosistema |
|------|---------------------|------------|
| USA | 45% | Maduro |
| UK | 18% | Robusto |
| India | 12% | Emergente |

### 3. Perfil Ideal de InversiÃ³n
```
Sector: FinTech/HealthTech
Stage: Series A ($5-15M)
Location: USA/UK
Age: 2-4 aÃ±os
Team Size: 10-50
Score: >75/100
```

## ğŸ’¼ Recomendaciones

### Corto Plazo (0-6 meses)

1. Invertir $50M en portafolio FinTech USA
2. Abrir oficina en UK para deal flow
3. Contratar especialista en HealthTech

### Medio Plazo (6-12 meses)

1. Expandir a Israel y Singapore
2. Lanzar fondo especÃ­fico para AI/ML
3. Establecer relaciones con aceleradoras top

### Largo Plazo (12+ meses)

1. Evaluar mercados emergentes (India, Brasil)
2. Desarrollar tesis de inversiÃ³n por vertical
3. Construir red de co-inversionistas

## ğŸ“ˆ MÃ©tricas de Ã‰xito

- ROI objetivo: 3.2x en 5 aÃ±os
- Tasa de Ã©xito portafolio: >40%
- Tiempo promedio a exit: 4-6 aÃ±os
```

### âœ… Checklist

- [ ] Insights documentados
- [ ] Framework aplicado
- [ ] Resumen ejecutivo creado
- [ ] Commit: `docs: Add insights`

---

## 13. Entregables Finales

### ğŸ“¦ Checklist Completo

#### CÃ³digo y Notebooks

- [ ] 5 notebooks completos y ejecutables
- [ ] CÃ³digo modular en `src/`
- [ ] Tests bÃ¡sicos en `tests/`
- [ ] Sin errores al ejecutar end-to-end

#### DocumentaciÃ³n

- [ ] README.md completo
- [ ] Executive summary
- [ ] Data dictionary
- [ ] API documentation

#### Visualizaciones

- [ ] Dashboard ejecutivo (GridSpec)
- [ ] MÃ­nimo 6 visualizaciones guardadas
- [ ] Todas en `reports/figures/`

#### Git/GitHub

- [ ] MÃ­nimo 20 commits descriptivos
- [ ] README con badges
- [ ] .gitignore configurado
- [ ] Repositorio pÃºblico

---

## 14. Criterios de EvaluaciÃ³n

### ğŸ“Š RÃºbrica de EvaluaciÃ³n (Total: 100 puntos)

| CategorÃ­a | Peso | Criterios | Puntos |
|-----------|------|-----------|--------|
| **Uso de APIs** | 20% | - 3 APIs funcionando correctamente (15 pts)<br>- Manejo de errores robusto (5 pts) | 20 |
| **JOINs en Pandas** | 15% | - 3 tipos diferentes de JOIN (9 pts)<br>- JustificaciÃ³n de cada tipo (6 pts) | 15 |
| **Feature Engineering** | 15% | - MÃ­nimo 5 features creadas (10 pts)<br>- Features aportan valor al negocio (5 pts) | 15 |
| **Visualizaciones** | 20% | - Dashboard con GridSpec (10 pts)<br>- MÃ­nimo 6 visualizaciones profesionales (10 pts) | 20 |
| **Insights de Negocio** | 20% | - 5 preguntas respondidas (10 pts)<br>- Recomendaciones accionables (10 pts) | 20 |
| **DocumentaciÃ³n** | 10% | - README completo (3 pts)<br>- Executive summary (4 pts)<br>- CÃ³digo comentado (3 pts) | 10 |

### âœ… Puntaje MÃ­nimo para Aprobar: 70/100

### ğŸ† Niveles de Logro

| Rango | Nivel | DescripciÃ³n |
|-------|-------|-------------|
| 90-100 | **Excelente** | Listo para portfolio profesional |
| 80-89 | **Muy Bueno** | Proyecto sÃ³lido, mejoras menores |
| 70-79 | **Bueno** | Cumple requisitos, necesita refinamiento |
| <70 | **Insuficiente** | Requiere completar elementos faltantes |

---

## 15. Recursos y Troubleshooting

### ğŸ“š DocumentaciÃ³n Oficial

- **Pandas:** https://pandas.pydata.org/docs/
- **Matplotlib:** https://matplotlib.org/stable/gallery/
- **Kaggle API:** https://www.kaggle.com/docs/api
- **CoinGecko:** https://www.coingecko.com/en/api/documentation
- **REST Countries:** https://restcountries.com/
- **World Bank:** https://datahelpdesk.worldbank.org/knowledgebase/articles/889392

### ğŸ› Troubleshooting ComÃºn

#### Problema 1: Kaggle API no funciona
```bash
# SoluciÃ³n:
# 1. Verificar kaggle.json existe
ls ~/.kaggle/kaggle.json

# 2. Verificar permisos (Linux/Mac)
chmod 600 ~/.kaggle/kaggle.json

# 3. Probar autenticaciÃ³n
python -c "from kaggle.api.kaggle_api_extended import KaggleApi; api = KaggleApi(); api.authenticate(); print('âœ… OK')"
```

#### Problema 2: Error de encoding al cargar CSV
```python
# SoluciÃ³n: Usar data_loader.py que maneja encoding automÃ¡ticamente
from src.data.data_loader import load_raw

df = load_raw('archivo.csv')  # Detecta encoding automÃ¡ticamente
```

#### Problema 3: APIs con rate limit
```python
# SoluciÃ³n: Agregar delays entre requests
import time

for i in range(10):
    response = requests.get(url)
    time.sleep(1)  # Esperar 1 segundo entre llamadas
```

#### Problema 4: Error en JOINs
```python
# SoluciÃ³n: Verificar antes y despuÃ©s del merge
print(f"Antes: df1={len(df1)}, df2={len(df2)}")

result = pd.merge(df1, df2, on='key', how='left')

print(f"DespuÃ©s: {len(result)}")
print(f"Nulos creados: {result.isnull().sum()}")
```

#### Problema 5: GridSpec no muestra bien
```python
# SoluciÃ³n: Usar tight_layout() y tamaÃ±os adecuados
fig = plt.figure(figsize=(16, 12))  # TamaÃ±o grande
# ... crear subplots ...
plt.tight_layout()
plt.subplots_adjust(top=0.95)  # Ajustar para tÃ­tulo
plt.show()
```

### ğŸ’¡ Tips Profesionales

#### Tip 1: Commits Frecuentes
```bash
# Commit despuÃ©s de cada fase completada
git add .
git commit -m "âœ¨ feat: Completada Fase 1 - Data Acquisition"
git push
```

#### Tip 2: Prueba Incremental
```python
# No esperes a tener todo el cÃ³digo para probar
# Prueba cada funciÃ³n inmediatamente

def mi_funcion(x):
    return x * 2

# Probar inmediatamente
assert mi_funcion(5) == 10
print("âœ… FunciÃ³n funciona")
```

#### Tip 3: DocumentaciÃ³n en el Momento
```python
# Documenta MIENTRAS escribes cÃ³digo, no despuÃ©s
def calcular_tasa_exito(df, sector):
    """
    Calcula la tasa de Ã©xito de startups en un sector.
    
    Args:
        df: DataFrame con columnas 'sector' y 'status'
        sector: Nombre del sector a analizar
        
    Returns:
        float: Porcentaje de Ã©xito (0-100)
    """
    # Tu cÃ³digo aquÃ­
```

#### Tip 4: Usa Variables Descriptivas
```python
# âŒ MAL
df1 = df[df['c'] == 'x']
df2 = df1.groupby('y')['z'].sum()

# âœ… BIEN
operating_startups = df[df['status'] == 'operating']
funding_by_sector = operating_startups.groupby('sector')['funding_usd'].sum()
```

#### Tip 5: Manejo de Errores Siempre
```python
# âœ… Siempre usar try-except en llamadas a APIs
try:
    response = requests.get(url, timeout=10)
    response.raise_for_status()
    data = response.json()
except requests.exceptions.Timeout:
    print("â° Timeout - intenta de nuevo")
except requests.exceptions.HTTPError as e:
    print(f"âŒ Error HTTP: {e}")
except Exception as e:
    print(f"âŒ Error inesperado: {e}")
```

### ğŸš€ Optimizaciones Avanzadas

#### Para Datasets Grandes (>1GB)
```python
# Leer CSV en chunks
chunks = []
for chunk in pd.read_csv('huge_file.csv', chunksize=10000):
    # Procesar chunk
    chunk_processed = chunk[chunk['status'] == 'operating']
    chunks.append(chunk_processed)

df_final = pd.concat(chunks, ignore_index=True)
```

#### CachÃ© de APIs
```python
import pickle
from pathlib import Path

def fetch_with_cache(url, cache_file):
    """Fetch con cachÃ© local"""
    cache_path = Path(cache_file)
    
    if cache_path.exists():
        print("ğŸ“¦ Cargando desde cachÃ©")
        with open(cache_path, 'rb') as f:
            return pickle.load(f)
    
    print("ğŸŒ Descargando de API")
    response = requests.get(url)
    data = response.json()
    
    with open(cache_path, 'wb') as f:
        pickle.dump(data, f)
    
    return data
```

---

## ğŸ“ Recursos de Aprendizaje Adicionales

### ğŸ“– Lecturas Recomendadas

1. **"Python for Data Analysis" - Wes McKinney**
   - CapÃ­tulos 7-8: Data Cleaning and Preparation
   - CapÃ­tulos 9-10: Data Aggregation and Group Operations

2. **Kaggle Learn:**
   - Pandas Course: https://www.kaggle.com/learn/pandas
   - Data Visualization: https://www.kaggle.com/learn/data-visualization

3. **Real Python:**
   - Working with APIs: https://realpython.com/api-integration-in-python/
   - Pandas GroupBy: https://realpython.com/pandas-groupby/

### ğŸ¥ Videos Recomendados

1. **Data School (YouTube):**
   - Pandas Best Practices
   - Data Cleaning Workflow

2. **Corey Schafer:**
   - Matplotlib Tutorial Series
   - Pandas Tutorial Series

### ğŸ’¼ Proyectos Similares para InspiraciÃ³n

1. **Kaggle Notebooks:**
   - Buscar: "startup analysis", "venture capital analysis"
   - Filtrar por: Most Votes

2. **GitHub:**
   - Buscar: "startup investment analysis python"
   - Estudiar estructura de proyectos con muchas â­

---

## ğŸ¯ Plan de Trabajo Sugerido

### Semana 1: Fundamentos

- **Lunes:** Setup + Fase 0 (2h)
- **Martes:** Fase 1 - APIs (3h)
- **MiÃ©rcoles:** Fase 1 - Kaggle (2h)
- **Jueves:** Fase 2 - Limpieza (4h)
- **Viernes:** Repaso y consolidaciÃ³n (2h)

### Semana 2: AnÃ¡lisis

- **Lunes:** Fase 3 - Feature Engineering (4h)
- **Martes:** Fase 3 - ValidaciÃ³n (2h)
- **MiÃ©rcoles:** Fase 4 - EDA parte 1 (3h)
- **Jueves:** Fase 4 - EDA parte 2 (3h)
- **Viernes:** Fase 5 - JOINs (3h)

### Semana 3: VisualizaciÃ³n

- **Lunes:** Fase 6 - Dashboard base (4h)
- **Martes:** Fase 6 - Visualizaciones adicionales (3h)
- **MiÃ©rcoles:** Fase 7 - Insights (3h)
- **Jueves:** DocumentaciÃ³n (3h)
- **Viernes:** Refinamiento y entrega (4h)

---

## ğŸ“ Plantillas Ãštiles

### Template: Celda de Markdown Inicial
```markdown
# [NÃºmero]. [TÃ­tulo de la SecciÃ³n]

**Objetivo:** [QuÃ© vamos a lograr]

**Entrada:** [QuÃ© datos/archivos necesitamos]

**Salida:** [QuÃ© vamos a producir]

**DuraciÃ³n estimada:** [X minutos]
```

### Template: Commit Message
```bash
# Formato: <tipo>: <descripciÃ³n>

# Tipos:
# âœ¨ feat: Nueva funcionalidad
# ğŸ› fix: CorrecciÃ³n de bug
# ğŸ“ docs: DocumentaciÃ³n
# ğŸ¨ style: Formato (no afecta cÃ³digo)
# â™»ï¸ refactor: RefactorizaciÃ³n
# ğŸ§ª test: Agregar tests
# ğŸ”§ chore: Mantenimiento

# Ejemplos:
git commit -m "âœ¨ feat: Add CoinGecko API integration"
git commit -m "ğŸ› fix: Handle missing country_code in merge"
git commit -m "ğŸ“ docs: Add executive summary"
```

### Template: FunciÃ³n Documentada
```python
def nombre_funcion(param1: tipo1, param2: tipo2) -> tipo_retorno:
    """
    [DescripciÃ³n breve de una lÃ­nea]
    
    [DescripciÃ³n extendida opcional con mÃ¡s detalles
    sobre el propÃ³sito y comportamiento de la funciÃ³n]
    
    Args:
        param1: DescripciÃ³n del primer parÃ¡metro
        param2: DescripciÃ³n del segundo parÃ¡metro
        
    Returns:
        DescripciÃ³n de lo que retorna
        
    Raises:
        ErrorType: CuÃ¡ndo y por quÃ© se levanta este error
        
    Example:
        >>> resultado = nombre_funcion(valor1, valor2)
        >>> print(resultado)
        Salida esperada
    """
    # ImplementaciÃ³n
    pass
```

---

## ğŸ Checklist Final Pre-Entrega

### âœ… CÃ³digo

- [ ] Todos los notebooks ejecutan sin errores
- [ ] CÃ³digo en `src/` es modular y reutilizable
- [ ] No hay imports sin usar
- [ ] Variables tienen nombres descriptivos
- [ ] Funciones tienen docstrings

### âœ… Datos

- [ ] `data/raw/` tiene datos originales
- [ ] `data/processed/` tiene datos limpios
- [ ] `data/external/` tiene datos de APIs
- [ ] `.gitignore` excluye archivos grandes

### âœ… AnÃ¡lisis

- [ ] 5 preguntas de negocio respondidas
- [ ] MÃ­nimo 5 features creadas
- [ ] 3 tipos de JOINs usados y documentados
- [ ] EDA completo con hallazgos

### âœ… VisualizaciÃ³n

- [ ] Dashboard ejecutivo creado
- [ ] MÃ­nimo 6 visualizaciones
- [ ] Todas guardadas en `reports/figures/`
- [ ] Figuras de alta resoluciÃ³n (300 DPI)

### âœ… DocumentaciÃ³n

- [ ] README.md completo
- [ ] Executive summary escrito
- [ ] Data dictionary creado
- [ ] CÃ³digo comentado adecuadamente

### âœ… Git/GitHub

- [ ] MÃ­nimo 20 commits descriptivos
- [ ] Repositorio pÃºblico (o privado si prefieres)
- [ ] README con badges
- [ ] LICENSE incluida

### âœ… PresentaciÃ³n (Opcional)

- [ ] Slides ejecutivos (10-15 diapositivas)
- [ ] Video demo (5-10 minutos)
- [ ] Blog post explicando el proyecto

---

## ğŸ‰ Â¡Felicitaciones!

Si llegaste hasta aquÃ­ y completaste todos los pasos, has creado un proyecto de **nivel profesional** que puedes:

âœ… Agregar a tu **portfolio**  
âœ… Mostrar en **entrevistas de trabajo**  
âœ… Compartir en **LinkedIn**  
âœ… Usar como **referencia** para futuros proyectos  

### ğŸš€ PrÃ³ximos Pasos

1. **Publicar el proyecto:**
   - Escribe un post en LinkedIn
   - Comparte en comunidades de Data Science
   - Agrega al README badges de Python, Pandas, etc.

2. **Expandir el proyecto:**
   - Agregar modelos de ML para predicciÃ³n
   - Dashboard interactivo con Plotly/Dash
   - API REST con FastAPI
   - AutomatizaciÃ³n con Airflow

3. **Aprender mÃ¡s:**
   - SQL para bases de datos
   - Spark para Big Data
   - Machine Learning con scikit-learn
   - Deep Learning con TensorFlow

---

## ğŸ“ Soporte y Comunidad

### ğŸ’¬ DÃ³nde Pedir Ayuda

- **Stack Overflow:** Tag `pandas`, `matplotlib`, `python`
- **Reddit:** r/datascience, r/learnpython
- **Discord:** Python Discord Server
- **Kaggle Forums:** Discussions sobre datasets

### ğŸ¤ Contribuir al Proyecto

Si mejoras este proyecto, considera:
- Hacer un fork y enviar Pull Request
- Documentar mejoras en el README
- Compartir tus insights

---

## ğŸ“„ Licencia

Este proyecto educativo estÃ¡ bajo licencia MIT. Eres libre de:
- âœ… Usar el cÃ³digo
- âœ… Modificarlo
- âœ… Distribuirlo
- âœ… Usarlo comercialmente

**Ãšnica condiciÃ³n:** Mantener el aviso de copyright.

---

## ğŸ‘¤ Autor

**Anderson Sebastian Rubio Pacheco**
- GitHub: [@hamtrass59](https://github.com/hamtrass59)
- Email: hamtrass59@hotmail.com
- LinkedIn: [Tu perfil]

---

## ğŸ™ Agradecimientos

- **Platzi** por el bootcamp de Data Science
- **Kaggle** por los datasets pÃºblicos
- **Comunidad de Python** por las librerÃ­as open source
- **APIs pÃºblicas** por facilitar acceso a datos

---

**Ãšltima actualizaciÃ³n:** Octubre 2025  
**VersiÃ³n del documento:** 1.0.0  

---

## ğŸ“Œ Notas Finales

### âš ï¸ Advertencias Importantes

1. **No uses datos sensibles:** Este es un proyecto educativo con datos pÃºblicos
2. **Respeta rate limits:** No abuses de las APIs
3. **No versiones archivos grandes:** Usa `.gitignore` correctamente
4. **Cita tus fuentes:** Da crÃ©dito a datasets y APIs usadas

### ğŸ’¡ Consejos de un Data Scientist Senior

1. **"Perfect is the enemy of done"** - Entrega algo funcional primero, refina despuÃ©s
2. **Documenta mientras programas** - No dejes la documentaciÃ³n para el final
3. **Git commit frecuente** - Mejor muchos commits pequeÃ±os que uno grande
4. **Pregunta cuando te atores** - No pierdas 2 horas en algo que alguien te puede explicar en 5 minutos
5. **Portfolio > Certificados** - Un proyecto bien hecho vale mÃ¡s que 10 certificados

### ğŸ¯ Meta Final

Al completar este proyecto, habrÃ¡s demostrado:
- âœ… Capacidad de trabajar con datos reales
- âœ… IntegraciÃ³n de mÃºltiples fuentes
- âœ… Pensamiento analÃ­tico de negocio
- âœ… ComunicaciÃ³n de insights
- âœ… Buenas prÃ¡cticas de programaciÃ³n

**Â¡Ahora ve y construye algo increÃ­ble! ğŸš€**

---

_"Data is the new oil, but only if you know how to refine it."_  
_â€” AnÃ³nimo_