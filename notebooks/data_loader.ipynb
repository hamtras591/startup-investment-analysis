{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-22T18:30:25.102348Z",
     "start_time": "2025-10-22T18:30:20.801745Z"
    }
   },
   "source": [
    "# data_loader.py\n",
    "\"\"\"\n",
    "Universal Data Loader Module\n",
    "============================\n",
    "M√≥dulo reutilizable para cargar cualquier tipo de datos sin problemas de encoding.\n",
    "Autor: Anderson Sebastian Rubio Pacheco\n",
    "Versi√≥n: 1.0.0\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import chardet\n",
    "import logging\n",
    "from typing import Optional, Dict, Any, Union\n",
    "\n",
    "# Configurar logging\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "class UniversalDataLoader:\n",
    "    \"\"\"\n",
    "    Cargador universal de datos que maneja autom√°ticamente:\n",
    "    - Detecci√≥n de encoding\n",
    "    - M√∫ltiples formatos (CSV, Excel, JSON)\n",
    "    - Validaci√≥n de integridad\n",
    "    - Cach√© de archivos\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, cache_dir: Optional[str] = None, verbose: bool = True):\n",
    "        \"\"\"\n",
    "        Inicializa el cargador universal\n",
    "\n",
    "        Args:\n",
    "            cache_dir: Directorio para cach√© (opcional)\n",
    "            verbose: Mostrar mensajes detallados\n",
    "        \"\"\"\n",
    "        self.verbose = verbose\n",
    "        self.logger = logging.getLogger(self.__class__.__name__)\n",
    "        self.cache_dir = Path(cache_dir) if cache_dir else Path('.cache')\n",
    "        self._cache = {}\n",
    "\n",
    "        # Crear directorio de cach√© si no existe\n",
    "        if cache_dir:\n",
    "            self.cache_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    def load(self,\n",
    "             filepath: Union[str, Path],\n",
    "             force_reload: bool = False,\n",
    "             **kwargs) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        M√©todo principal - carga cualquier archivo autom√°ticamente\n",
    "\n",
    "        Args:\n",
    "            filepath: Ruta del archivo\n",
    "            force_reload: Forzar recarga ignorando cach√©\n",
    "            **kwargs: Argumentos adicionales para pandas\n",
    "\n",
    "        Returns:\n",
    "            DataFrame con los datos cargados\n",
    "        \"\"\"\n",
    "        filepath = Path(filepath)\n",
    "\n",
    "        # Verificar cach√©\n",
    "        cache_key = str(filepath.absolute())\n",
    "        if not force_reload and cache_key in self._cache:\n",
    "            self._log(\"üì¶ Cargando desde cach√©\")\n",
    "            return self._cache[cache_key]\n",
    "\n",
    "        # Detectar tipo de archivo\n",
    "        file_extension = filepath.suffix.lower()\n",
    "\n",
    "        if file_extension in ['.csv', '.txt', '.tsv']:\n",
    "            df = self._load_csv(filepath, **kwargs)\n",
    "        elif file_extension in ['.xlsx', '.xls']:\n",
    "            df = self._load_excel(filepath, **kwargs)\n",
    "        elif file_extension == '.json':\n",
    "            df = self._load_json(filepath, **kwargs)\n",
    "        elif file_extension == '.parquet':\n",
    "            df = self._load_parquet(filepath, **kwargs)\n",
    "        else:\n",
    "            raise ValueError(f\"Formato no soportado: {file_extension}\")\n",
    "\n",
    "        # Guardar en cach√©\n",
    "        self._cache[cache_key] = df\n",
    "\n",
    "        # Agregar metadata\n",
    "        df.attrs['source_file'] = str(filepath)\n",
    "        df.attrs['load_timestamp'] = pd.Timestamp.now()\n",
    "\n",
    "        return df\n",
    "\n",
    "    def _load_csv(self, filepath: Path, **kwargs) -> pd.DataFrame:\n",
    "        \"\"\"Carga archivos CSV con detecci√≥n autom√°tica de encoding\"\"\"\n",
    "\n",
    "        # Detectar separador si no se especifica\n",
    "        if 'sep' not in kwargs and 'delimiter' not in kwargs:\n",
    "            kwargs['sep'] = self._detect_delimiter(filepath)\n",
    "            self._log(f\"üìä Separador detectado: '{kwargs['sep']}'\")\n",
    "\n",
    "        # Detectar encoding si no se especifica\n",
    "        if 'encoding' not in kwargs:\n",
    "            encoding, confidence = self._detect_encoding(filepath)\n",
    "            kwargs['encoding'] = encoding\n",
    "            self._log(f\"üî§ Encoding detectado: {encoding} ({confidence:.1%} confianza)\")\n",
    "\n",
    "        # Intentar cargar\n",
    "        try:\n",
    "            df = pd.read_csv(filepath, **kwargs)\n",
    "            self._log(f\"‚úÖ CSV cargado: {df.shape[0]:,} filas √ó {df.shape[1]} columnas\")\n",
    "\n",
    "        except UnicodeDecodeError:\n",
    "            self._log(\"‚ö†Ô∏è Error de encoding, intentando con latin-1\")\n",
    "            kwargs['encoding'] = 'latin-1'\n",
    "            df = pd.read_csv(filepath, **kwargs)\n",
    "\n",
    "        except Exception as e:\n",
    "            self._log(f\"‚ö†Ô∏è Error, intentando con configuraci√≥n robusta\")\n",
    "            df = self._fallback_csv_load(filepath)\n",
    "\n",
    "        # Validar integridad\n",
    "        if self._check_corruption(df):\n",
    "            self._log(\"‚ö†Ô∏è Posible corrupci√≥n de caracteres detectada\")\n",
    "\n",
    "        return df\n",
    "\n",
    "    def _load_excel(self, filepath: Path, **kwargs) -> pd.DataFrame:\n",
    "        \"\"\"Carga archivos Excel\"\"\"\n",
    "        try:\n",
    "            df = pd.read_excel(filepath, **kwargs)\n",
    "            self._log(f\"‚úÖ Excel cargado: {df.shape[0]:,} filas √ó {df.shape[1]} columnas\")\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            self._log(f\"‚ùå Error cargando Excel: {e}\")\n",
    "            raise\n",
    "\n",
    "    def _load_json(self, filepath: Path, **kwargs) -> pd.DataFrame:\n",
    "        \"\"\"Carga archivos JSON\"\"\"\n",
    "        try:\n",
    "            df = pd.read_json(filepath, **kwargs)\n",
    "            self._log(f\"‚úÖ JSON cargado: {df.shape[0]:,} filas √ó {df.shape[1]} columnas\")\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            # Intentar con orientaciones diferentes\n",
    "            for orient in ['records', 'index', 'columns', 'values']:\n",
    "                try:\n",
    "                    df = pd.read_json(filepath, orient=orient)\n",
    "                    self._log(f\"‚úÖ JSON cargado con orient='{orient}'\")\n",
    "                    return df\n",
    "                except:\n",
    "                    continue\n",
    "            raise e\n",
    "\n",
    "    def _load_parquet(self, filepath: Path, **kwargs) -> pd.DataFrame:\n",
    "        \"\"\"Carga archivos Parquet (formato eficiente)\"\"\"\n",
    "        try:\n",
    "            df = pd.read_parquet(filepath, **kwargs)\n",
    "            self._log(f\"‚úÖ Parquet cargado: {df.shape[0]:,} filas √ó {df.shape[1]} columnas\")\n",
    "            return df\n",
    "        except ImportError:\n",
    "            self._log(\"‚ùå Instala 'pyarrow' para leer archivos Parquet\")\n",
    "            raise\n",
    "\n",
    "    def _detect_encoding(self, filepath: Path, sample_size: int = 100000) -> tuple:\n",
    "        \"\"\"Detecta el encoding del archivo\"\"\"\n",
    "        try:\n",
    "            with open(filepath, 'rb') as file:\n",
    "                raw_data = file.read(sample_size)\n",
    "                result = chardet.detect(raw_data)\n",
    "                return result['encoding'], result['confidence']\n",
    "        except:\n",
    "            return 'utf-8', 0.5\n",
    "\n",
    "    def _detect_delimiter(self, filepath: Path) -> str:\n",
    "        \"\"\"Detecta el delimitador del CSV\"\"\"\n",
    "        with open(filepath, 'r', encoding='latin-1', errors='ignore') as file:\n",
    "            first_line = file.readline()\n",
    "\n",
    "        # Contar ocurrencias de posibles delimitadores\n",
    "        delimiters = {\n",
    "            ',': first_line.count(','),\n",
    "            ';': first_line.count(';'),\n",
    "            '\\t': first_line.count('\\t'),\n",
    "            '|': first_line.count('|')\n",
    "        }\n",
    "\n",
    "        return max(delimiters, key=delimiters.get)\n",
    "\n",
    "    def _check_corruption(self, df: pd.DataFrame) -> bool:\n",
    "        \"\"\"Verifica si hay caracteres corruptos en el DataFrame\"\"\"\n",
    "        corruption_patterns = ['√É', '√Ç¬£', '√É¬±', '√É¬°', '√É¬©', '√Ç']\n",
    "\n",
    "        for col in df.select_dtypes(include=['object']).columns:\n",
    "            sample = df[col].astype(str).head(100).str.cat(sep=' ')\n",
    "            if any(pattern in sample for pattern in corruption_patterns):\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def _fallback_csv_load(self, filepath: Path) -> pd.DataFrame:\n",
    "        \"\"\"M√©todo de respaldo para CSVs problem√°ticos\"\"\"\n",
    "        return pd.read_csv(\n",
    "            filepath,\n",
    "            encoding='latin-1',\n",
    "            sep=None,  # Detectar autom√°ticamente\n",
    "            engine='python',\n",
    "            on_bad_lines='skip',\n",
    "            encoding_errors='ignore'\n",
    "        )\n",
    "\n",
    "    def _log(self, message: str):\n",
    "        \"\"\"Imprime mensaje si verbose est√° activo\"\"\"\n",
    "        if self.verbose:\n",
    "            print(message)\n",
    "\n",
    "    def save_clean(self,\n",
    "                   df: pd.DataFrame,\n",
    "                   filepath: Union[str, Path],\n",
    "                   format: str = 'auto') -> None:\n",
    "        \"\"\"\n",
    "        Guarda el DataFrame en formato limpio y estandarizado\n",
    "\n",
    "        Args:\n",
    "            df: DataFrame a guardar\n",
    "            filepath: Ruta donde guardar\n",
    "            format: Formato ('csv', 'excel', 'parquet', 'auto')\n",
    "        \"\"\"\n",
    "        filepath = Path(filepath)\n",
    "\n",
    "        if format == 'auto':\n",
    "            format = filepath.suffix[1:] if filepath.suffix else 'csv'\n",
    "\n",
    "        if format == 'csv':\n",
    "            df.to_csv(filepath, encoding='utf-8', index=False)\n",
    "            self._log(f\"üíæ Guardado como CSV UTF-8: {filepath}\")\n",
    "        elif format == 'excel':\n",
    "            df.to_excel(filepath, index=False)\n",
    "            self._log(f\"üíæ Guardado como Excel: {filepath}\")\n",
    "        elif format == 'parquet':\n",
    "            df.to_parquet(filepath, index=False)\n",
    "            self._log(f\"üíæ Guardado como Parquet: {filepath}\")\n",
    "        else:\n",
    "            raise ValueError(f\"Formato no soportado: {format}\")\n",
    "\n",
    "    def get_info(self, df: pd.DataFrame) -> Dict[str, Any]:\n",
    "        \"\"\"Obtiene informaci√≥n detallada del DataFrame\"\"\"\n",
    "        info = {\n",
    "            'shape': df.shape,\n",
    "            'columns': df.columns.tolist(),\n",
    "            'dtypes': df.dtypes.to_dict(),\n",
    "            'memory_mb': df.memory_usage(deep=True).sum() / 1024 ** 2,\n",
    "            'nulls': df.isnull().sum().to_dict(),\n",
    "            'source': df.attrs.get('source_file', 'Unknown'),\n",
    "            'loaded_at': df.attrs.get('load_timestamp', 'Unknown')\n",
    "        }\n",
    "        return info\n",
    "\n",
    "# Funciones de conveniencia (shortcuts)\n",
    "def load_data(filepath: Union[str, Path], **kwargs) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Funci√≥n r√°pida para cargar cualquier archivo\n",
    "\n",
    "    Uso:\n",
    "        df = load_data('archivo.csv')\n",
    "        df = load_data('archivo.xlsx', sheet_name='Hoja1')\n",
    "    \"\"\"\n",
    "    loader = UniversalDataLoader(verbose=True)\n",
    "    return loader.load(filepath, **kwargs)\n",
    "\n",
    "\n",
    "def quick_load(filepath: Union[str, Path]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Carga r√°pida sin mensajes\n",
    "\n",
    "    Uso:\n",
    "        df = quick_load('archivo.csv')\n",
    "    \"\"\"\n",
    "    loader = UniversalDataLoader(verbose=False)\n",
    "    return loader.load(filepath)\n",
    "\n",
    "\n",
    "def load_and_clean(filepath: Union[str, Path]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Carga y limpia autom√°ticamente\n",
    "\n",
    "    Uso:\n",
    "        df = load_and_clean('archivo.csv')\n",
    "    \"\"\"\n",
    "    loader = UniversalDataLoader(verbose=True)\n",
    "    df = loader.load(filepath)\n",
    "\n",
    "    # Limpieza autom√°tica b√°sica\n",
    "    initial_shape = df.shape\n",
    "\n",
    "    # Eliminar filas completamente vac√≠as\n",
    "    df = df.dropna(how='all')\n",
    "\n",
    "    # Eliminar columnas completamente vac√≠as\n",
    "    df = df.dropna(axis=1, how='all')\n",
    "\n",
    "    # Eliminar duplicados\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    final_shape = df.shape\n",
    "\n",
    "    if initial_shape != final_shape:\n",
    "        print(f\"üßπ Limpieza: {initial_shape} ‚Üí {final_shape}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Para importar directamente las funciones m√°s usadas\n",
    "__all__ = ['UniversalDataLoader', 'load_data', 'quick_load', 'load_and_clean']\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "10a08f550f9a2f3a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
